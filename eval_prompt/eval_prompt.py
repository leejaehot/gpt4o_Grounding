from openai import OpenAI
import os
import base64
import re, ast
import cv2
import json
from tqdm import tqdm

from dotenv import load_dotenv
load_dotenv()
# .env ì— ê¸°ì¬ëœ OPENAI_API_KEYê°€ os.environì— í™˜ê²½ë³€ìˆ˜ë¡œ ì €ì¥.
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", None)
if OPENAI_API_KEY is None:
    raise ValueError("OPENAI_API_KEY not found in environment variables. Please set it in .env.")

client = OpenAI(
  api_key=OPENAI_API_KEY,  # this is also the default, it can be omitted
)


""" ê¸€ë¡œë²Œ ë³€ìˆ˜ ì„¤ì • """
ENGINE = 'gpt-4o'
MAX_TOKENS = 4096 # ìµœëŒ€ í† í° ìˆ˜ ì„¤ì •
# ENCODER = tiktoken.encoding_for_model(ENGINE) # ëª¨ë¸ì— ë§ëŠ” í† í° ì¸ì½”ë”© ì„¤ì •


center_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/Grounding DINO Center.jpg"
center_indexing_bold_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/GroundingDINO Center Bold.jpg"
jwasang_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/jwasang.jpg"
jwaha_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/jwaha.jpg"
woosang_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/woosang.jpg"
wooha_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/wooha.jpg"
yellow_bbox_indexing_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicin_pic/GroundingDINO bbox yellow.jpg"


indexing_image = center_indexing_image
original_image = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/medicine_image.jpeg"

# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©
with open(indexing_image, "rb") as image_file:
    base64_image_idx = base64.b64encode(image_file.read()).decode('utf-8')

# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©
with open(original_image, "rb") as image_file:
    base64_image_og = base64.b64encode(image_file.read()).decode('utf-8')

# Helper function to interact with GPT-4
def ask_gpt(prompt):
    
    system_prompt = """
    Let's think step by step. ìƒê°ì€ ì˜ì–´ë¡œ í•˜ë˜, ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œë§Œ í•´. ë„Œ ì§€ê¸ˆë¶€í„° ì•½ì‚¬ì•¼.
    """
    
    instruction_prompt = """
    ë‹¤ìŒì€ OVDëª¨ë¸ì„ í†µí•´ ë‚˜ì˜¨ ì „ê²½ì˜ ëª¨ë“  ë¬¼ì²´ë“¤ì— ëŒ€í•œ bboxì™€ index ì •ë³´ì•¼.
    original image size = 4032*3024
    Detected 16 bounding boxes.

    'index_text' : 1, 'bbox' : {x_min=2106, y_min=303, x_max=2992, y_max=880}
    'index_text' : 2, 'bbox' : {x_min=1710, y_min=155, x_max=1983, y_max=890}
    'index_text' : 3, 'bbox' : {x_min=3212, y_min=1076, x_max=3565, y_max=1966}
    'index_text' : 4, 'bbox' : {x_min=2529, y_min=1950, x_max=3949, y_max=2995}
    'index_text' : 5, 'bbox' : {x_min=1801, y_min=1820, x_max=2543, y_max=2932}
    'index_text' : 6, 'bbox' : {x_min=1118, y_min=1806, x_max=1816, y_max=2988}
    'index_text' : 7, 'bbox' : {x_min=1003, y_min=582, x_max=1607, y_max=753}
    'index_text' : 8, 'bbox' : {x_min=183, y_min=1847, x_max=1122, y_max=2443}
    'index_text' : 9, 'bbox' : {x_min=2570, y_min=929, x_max=3181, y_max=1951}
    'index_text' : 10, 'bbox' : {x_min=1216, y_min=1321, x_max=2025, y_max=1799}
    'index_text' : 11, 'bbox' : {x_min=287, y_min=2391, x_max=1118, y_max=2934}
    'index_text' : 12, 'bbox' : {x_min=217, y_min=880, x_max=1134, y_max=1384}
    'index_text' : 13, 'bbox' : {x_min=234, y_min=1322, x_max=1210, y_max=1888}
    'index_text' : 14, 'bbox' : {x_min=2042, y_min=942, x_max=2567, y_max=1805}
    'index_text' : 15, 'bbox' : {x_min=274, y_min=206, x_max=821, y_max=822}
    'index_text' : 16, 'bbox' : {x_min=1172, y_min=890, x_max=2001, y_max=1364}
    
    ------------------------------------

    ì´ì œ {Userì˜ ëª¨í˜¸í•œ ëª…ë ¹ì–´}ê°€ ì œì‹œë  ê±°ì•¼. original imageì™€ indexing imageë¥¼ ëª¨ë‘ ê³ ë ¤í•´ì„œ ì´ ìƒí™©ì— ì ì ˆí•œ ì•½ì„ ë²ˆí˜¸ë¡œ ì„¤ëª…í•´ì¤˜. ì´ ë•Œ, ì‚¬ì§„ ë‚´ì˜ ë¬¼ì²´ ë³„ ì¤‘ì•™ì— ìœ„ì¹˜í•œ index ìˆ«ì textë¥¼ ì°¸ê³ í•´. ë¬´ì¡°ê±´ ì˜ˆì‹œ ì„¤ëª…ì˜ í˜•ì‹ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜. don't output the json script.
    <ì˜ˆì‹œ ì„¤ëª…>
    answer : {'object_name': 'ë¬¼ì²´ì´ë¦„1', 'info': 'ë¬¼ì²´íŠ¹ì§•1', 'index_text': 'ë¬¼ì²´ ìœ„ì— ê·¸ë ¤ì§„ ìˆ«ì'}
    
    if, ì ì ˆí•œ ê²Œ ì—†ìœ¼ë©´ answer : {'object_name': "None", 'info': '', 'index_text': ''}
    """
    
    response = client.chat.completions.create(
        model=ENGINE,
        messages=[
            {
                "role": "system", "content": system_prompt
            },
            {
                "role": "user", "content": instruction_prompt
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64, {base64_image_og}",
                        }
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64, {base64_image_idx}",
                        }
                    },
                ],
            },
        ],
        max_tokens=MAX_TOKENS,
        temperature=0,
    )
    
    # breakpoint()
    return response.choices[0].message.content

# JSON íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_json_file(file_path):
    """JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        return data
    except Exception as e:
        print(f"Error loading JSON file: {e}")
        return []

# grounding_DINO_bbox.json ë¡œë“œ í•¨ìˆ˜
def load_grounding_dino_bbox(file_path):
    """Grounding DINO BBox ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            data = json.load(file)
        return data
    except Exception as e:
        print(f"Error loading grounding DINO bbox JSON file: {e}")
        return {}

def parse_response(response):
    """
    GPT-4ì˜ ì‘ë‹µì—ì„œ object_name, info, index_textë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    response: GPT-4ì˜ ì‘ë‹µ ë¬¸ìì—´
    """
    try:
        # 'answer :' ì´í›„ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        if "answer :" in response:
            response = response.split("answer :", 1)[1].strip()
        
        # ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        parsed_response = ast.literal_eval(response)
        return parsed_response
    except Exception as e:
        print(f"Error parsing response: {e}")
        return {}

# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
def evaluate_model(data, grounding_dino_data):
    """ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ GPT-4 ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    correct = 0
    total = len(data)
    # object_name -> index_text ë§¤í•‘ ìƒì„±
    object_to_index_map = {
        str(item["object_name"]): str(item["index_text"])
        for item in grounding_dino_data.get("detected_bounding_boxes", [])
    }
    
    for item in tqdm(data):
        query = item["query"]
        gt = item["gt"]
        expected_index = []
        for gt_name in gt:
            expected_index.append(object_to_index_map.get(gt_name, ""))  # gt[0]ê³¼ ë§¤í•‘ëœ index_text
        
        # GPT-4 í˜¸ì¶œ
        try:
            response = ask_gpt(query)
            print(f"GPT Response for Index {item['index']}, Query '{query}':\n{response}")
        except Exception as e:
            print(f"Error querying GPT-4 for index {item['index']}: {e}")
            continue
        
        # responseë¥¼ dictionaryë¡œ ë³€í™˜
        try:
            response_dict = parse_response(response)  # ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ì„ Python dictë¡œ ë³€í™˜
        except (ValueError, SyntaxError):
            print(f"Invalid response format for index {item['index']}: {response}")
            continue
        
        
        # object_nameê³¼ index_text ë¹„êµ
        if (
            response_dict.get("object_name") in gt  # object_nameì´ gtì™€ ê°™ìŒ
            and response_dict.get("index_text") in expected_index  # index_textê°€ ì‚¬ì „ì •ì˜ëœ indexì™€ ê°™ìŒ
        ):
            correct += 1
        print(f"gt : {gt}")
        print(f"correct/total = {correct}/{total}\n")
    
    # ì •í™•ë„ ê³„ì‚°
    accuracy = correct / total if total > 0 else 0
    return accuracy

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    # JSON íŒŒì¼ ê²½ë¡œ
    eval_file_path = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/eval_prompt/prompt_dataset_level4.json"
    grounding_dino_path = "/Users/leejaehot/leejaehot_main/sejongğŸ«/4-2/íŒ¨í„´ì¸ì‹(ì¬)/a100_backup/src/gpt4o_api/eval_prompt/grounding_DINO_bbox.json"
    
    # ë°ì´í„° ë¡œë“œ
    data = load_json_file(eval_file_path)
    grounding_dino_data = load_grounding_dino_bbox(grounding_dino_path)
    if not data or not grounding_dino_data:
        print("Failed to load data or grounding DINO bounding box data. Exiting.")
    else:
        # ëª¨ë¸ í‰ê°€
        accuracy = evaluate_model(data, grounding_dino_data)
        print(f"Accuracy: {accuracy:.2f}")
        